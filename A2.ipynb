{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\botna\\AppData\\Local\\Temp\\ipykernel_25788\\1863439292.py:12: DtypeWarning: Columns (12,15,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  filtered_data_last_6_years = pd.read_csv('datasets/filtered_data_last_6_years.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "STN         0\n",
       "YYYYMMDD    0\n",
       "H           0\n",
       "DD          0\n",
       "FH          0\n",
       "FF          0\n",
       "FX          0\n",
       "T           0\n",
       "T10N        0\n",
       "TD          0\n",
       "SQ          0\n",
       "Q           0\n",
       "DR          0\n",
       "RH          0\n",
       "P           0\n",
       "VV          0\n",
       "N           0\n",
       "U           0\n",
       "WW          0\n",
       "IX          0\n",
       "M           0\n",
       "R           0\n",
       "S           0\n",
       "O           0\n",
       "Y           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "A2 = pd.read_csv('datasets/A2.csv')\n",
    "\n",
    "# Drop the specified columns\n",
    "columns_to_drop = ['Hour', 'Station', 'Date', 'WindDirection', 'WindSpeedAvg', 'WindSpeed',\n",
    "                   'WindGust', 'Temperature', 'MinTemp10cm', 'DewPoint', 'SunshineDuration',\n",
    "                   'GlobalRadiation', 'PrecipitationDuration', 'PrecipitationAmount',\n",
    "                   'AirPressure', 'Visibility', 'CloudCover', 'Humidity', 'Weather',\n",
    "                   'WeatherCode', 'Fog', 'Rain', 'Snow', 'Thunder', 'IceFormation']\n",
    "A2 = A2.drop(columns=columns_to_drop)\n",
    "\n",
    "filtered_data_last_6_years = pd.read_csv('datasets/filtered_data_last_6_years.csv')\n",
    "# Filter filtered_data_last_6_years to include only rows where STN == 370\n",
    "filtered_data_last_6_years = filtered_data_last_6_years[filtered_data_last_6_years['STN'] == 370]\n",
    "\n",
    "filtered_data_last_6_years.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'to_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimeFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 3: Convert date columns to datetime format\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileEnd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_date\u001b[49m(A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileEnd\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_date(A2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m filtered_data_last_6_years[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYYYYMMDD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_date(filtered_data_last_6_years[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYYYYMMDD\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'to_date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Ensure \"H\" column in filtered_data_last_6_years is in the correct format (integer representing hour)\n",
    "filtered_data_last_6_years['H'] = filtered_data_last_6_years['H'].astype(int)\n",
    "\n",
    "# Step 2: Extract hour from \"TijdFileBegin\" and add as column \"H\" in filtered_highways_traffic_data\n",
    "A2['TimeFileEnd'] = pd.to_datetime(A2['TimeFileEnd'], format='%H:%M:%S', errors='coerce')\n",
    "A2['TimeFileStart'] = pd.to_datetime(A2['TimeFileStart'], format='%H:%M:%S', errors='coerce')\n",
    "A2['H'] = A2['TimeFileStart'].dt.hour\n",
    "\n",
    "# Step 3: Convert date columns to datetime format\n",
    "A2['DateFileEnd'] = pd.to_datetime(A2['DateFileEnd'], errors='coerce')\n",
    "A2['DateFileStart'] = pd.to_datetime(A2['DateFileStart'], errors='coerce')\n",
    "filtered_data_last_6_years['YYYYMMDD'] = pd.to_datetime(filtered_data_last_6_years['YYYYMMDD'], errors='coerce')\n",
    "\n",
    "# # Step 4: Map RouteNum to weather stations\n",
    "# weather_station_mapping = {\n",
    "#     15: 350,\n",
    "#     50: 275,\n",
    "#     2: 370,\n",
    "#     325: 275\n",
    "# }\n",
    "\n",
    "# A2['STN'] = A2['RouteNumber'].map(weather_station_mapping)\n",
    "\n",
    "# Step 5: Join the datasets on \"DateFileStart\" and \"H\"\n",
    "a2 = pd.merge(\n",
    "    A2,\n",
    "    filtered_data_last_6_years,\n",
    "    left_on=['DateFileStart', 'H'],\n",
    "    right_on=['YYYYMMDD', 'H'],\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "# Display the merged DataFrame\n",
    "a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16, 17,  8, 18, 14, 15,  9]),\n",
       " <DatetimeArray>\n",
       " ['1900-01-01 16:30:00', '1900-01-01 17:09:00', '1900-01-01 17:31:00',\n",
       "  '1900-01-01 17:14:00', '1900-01-01 17:54:00', '1900-01-01 17:04:00',\n",
       "  '1900-01-01 08:44:00', '1900-01-01 08:32:00', '1900-01-01 08:58:00',\n",
       "  '1900-01-01 08:53:00',\n",
       "  ...\n",
       "  '1900-01-01 17:02:33', '1900-01-01 08:49:30', '1900-01-01 17:46:31',\n",
       "  '1900-01-01 18:00:31', '1900-01-01 18:07:31', '1900-01-01 18:11:31',\n",
       "  '1900-01-01 14:57:30', '1900-01-01 14:02:30', '1900-01-01 14:51:31',\n",
       "  '1900-01-01 15:32:31']\n",
       " Length: 2216, dtype: datetime64[ns],\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_H_A21 = A2['H'].unique()\n",
    "unique_H_A2 = A2['TimeFileStart'].unique()\n",
    "unique_H_filtered = filtered_data_last_6_years['H'].unique()\n",
    "\n",
    "unique_H_A21, unique_H_A2, unique_H_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27720"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2['YYYYMMDD'].isna().sum()\n",
    "# a2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the hours in 'H' column and convert to time type\n",
    "a2['H'] = a2['H'].apply(lambda x: f'{x:02d}:00:00' if x != 24 else '00:00:00')\n",
    "a2['H'] = pd.to_datetime(a2['H'], format='%H:%M:%S').dt.time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLSituationNumber</th>\n",
       "      <th>DateFileStart</th>\n",
       "      <th>DateFileEnd</th>\n",
       "      <th>TimeFileStart</th>\n",
       "      <th>TimeFileEnd</th>\n",
       "      <th>FileSeverity</th>\n",
       "      <th>AvgLength</th>\n",
       "      <th>FileDuration</th>\n",
       "      <th>HectometerHead</th>\n",
       "      <th>HectometerTail</th>\n",
       "      <th>...</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Weather</th>\n",
       "      <th>WeatherCode</th>\n",
       "      <th>Fog</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Snow</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>IceFormation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>94</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49710</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49711</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49712</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49713</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49714</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49715 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NLSituationNumber DateFileStart DateFileEnd TimeFileStart TimeFileEnd  \\\n",
       "0                    NaN           NaT         NaT           NaT         NaT   \n",
       "1                    NaN           NaT         NaT           NaT         NaT   \n",
       "2                    NaN           NaT         NaT           NaT         NaT   \n",
       "3                    NaN           NaT         NaT           NaT         NaT   \n",
       "4                    NaN           NaT         NaT           NaT         NaT   \n",
       "...                  ...           ...         ...           ...         ...   \n",
       "49710                NaN           NaT         NaT           NaT         NaT   \n",
       "49711                NaN           NaT         NaT           NaT         NaT   \n",
       "49712                NaN           NaT         NaT           NaT         NaT   \n",
       "49713                NaN           NaT         NaT           NaT         NaT   \n",
       "49714                NaN           NaT         NaT           NaT         NaT   \n",
       "\n",
       "       FileSeverity  AvgLength  FileDuration  HectometerHead  HectometerTail  \\\n",
       "0               NaN        NaN           NaN             NaN             NaN   \n",
       "1               NaN        NaN           NaN             NaN             NaN   \n",
       "2               NaN        NaN           NaN             NaN             NaN   \n",
       "3               NaN        NaN           NaN             NaN             NaN   \n",
       "4               NaN        NaN           NaN             NaN             NaN   \n",
       "...             ...        ...           ...             ...             ...   \n",
       "49710           NaN        NaN           NaN             NaN             NaN   \n",
       "49711           NaN        NaN           NaN             NaN             NaN   \n",
       "49712           NaN        NaN           NaN             NaN             NaN   \n",
       "49713           NaN        NaN           NaN             NaN             NaN   \n",
       "49714           NaN        NaN           NaN             NaN             NaN   \n",
       "\n",
       "       ...  Visibility CloudCover Humidity Weather WeatherCode Fog Rain Snow  \\\n",
       "0      ...          22          8       96      23           7   0    1    0   \n",
       "1      ...          47          8       94      23           7   0    1    0   \n",
       "2      ...          56          8       93      10           7   0    0    0   \n",
       "3      ...          57          8       92      10           7   0    0    0   \n",
       "4      ...          56          8       92      10           7   0    0    0   \n",
       "...    ...         ...        ...      ...     ...         ...  ..  ...  ...   \n",
       "49710  ...          83          8       52                   5   0    0    0   \n",
       "49711  ...          83          8       51                   5   0    0    0   \n",
       "49712  ...          83          8       54                   5   0    0    0   \n",
       "49713  ...          83          8       57                   5   0    0    0   \n",
       "49714  ...          83          8       59                   7   0    0    0   \n",
       "\n",
       "       Thunder  IceFormation  \n",
       "0            0             0  \n",
       "1            0             0  \n",
       "2            0             0  \n",
       "3            0             0  \n",
       "4            0             0  \n",
       "...        ...           ...  \n",
       "49710        0             0  \n",
       "49711        0             0  \n",
       "49712        0             0  \n",
       "49713        0             0  \n",
       "49714        0             0  \n",
       "\n",
       "[49715 rows x 44 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the new column names\n",
    "column_mapping = {\n",
    "    'STN': 'Station',\n",
    "    'YYYYMMDD': 'Date',\n",
    "    'H': 'Hour',\n",
    "    'DD': 'WindDirection',\n",
    "    'FH': 'WindSpeedAvg',\n",
    "    'FF': 'WindSpeed',\n",
    "    'FX': 'WindGust',\n",
    "    'T': 'Temperature',\n",
    "    'T10N': 'MinTemp10cm',\n",
    "    'TD': 'DewPoint',\n",
    "    'SQ': 'SunshineDuration',\n",
    "    'Q': 'GlobalRadiation',\n",
    "    'DR': 'PrecipitationDuration',\n",
    "    'RH': 'PrecipitationAmount',\n",
    "    'P': 'AirPressure',\n",
    "    'VV': 'Visibility',\n",
    "    'N': 'CloudCover',\n",
    "    'U': 'Humidity',\n",
    "    'WW': 'Weather',\n",
    "    'IX': 'WeatherCode',\n",
    "    'M': 'Fog',\n",
    "    'R': 'Rain',\n",
    "    'S': 'Snow',\n",
    "    'O': 'Thunder',\n",
    "    'Y': 'IceFormation'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "a2.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLSituationNumber             float64\n",
       "DateFileStart          datetime64[ns]\n",
       "DateFileEnd            datetime64[ns]\n",
       "TimeFileStart          datetime64[ns]\n",
       "TimeFileEnd            datetime64[ns]\n",
       "FileSeverity                  float64\n",
       "AvgLength                     float64\n",
       "FileDuration                  float64\n",
       "HectometerHead                float64\n",
       "HectometerTail                float64\n",
       "RouteNumber                   float64\n",
       "HectometerDirection            object\n",
       "HeadSegmentFrom                object\n",
       "HeadSegmentTo                  object\n",
       "TrajectoryFrom                 object\n",
       "TrajectoryTo                   object\n",
       "CauseGroundDetail              object\n",
       "WayOfTraffic                   object\n",
       "H                              object\n",
       "STN                             int64\n",
       "YYYYMMDD               datetime64[ns]\n",
       "DD                              int64\n",
       "FH                              int64\n",
       "FF                              int64\n",
       "FX                              int64\n",
       "T                               int64\n",
       "T10N                           object\n",
       "TD                              int64\n",
       "SQ                              int64\n",
       "Q                               int64\n",
       "DR                             object\n",
       "RH                              int64\n",
       "P                               int64\n",
       "VV                             object\n",
       "N                              object\n",
       "U                               int64\n",
       "WW                             object\n",
       "IX                              int64\n",
       "M                              object\n",
       "R                              object\n",
       "S                              object\n",
       "O                              object\n",
       "Y                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing float columns: []\n",
      "Missing integer columns: []\n",
      "Missing categorical columns: []\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49715 entries, 0 to 49714\n",
      "Data columns (total 68 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   NLSituationNumber        5129 non-null   float64       \n",
      " 1   DateFileStart            5129 non-null   datetime64[ns]\n",
      " 2   DateFileEnd              5129 non-null   datetime64[ns]\n",
      " 3   TimeFileStart            0 non-null      datetime64[ns]\n",
      " 4   TimeFileEnd              0 non-null      datetime64[ns]\n",
      " 5   FileSeverity             5129 non-null   float64       \n",
      " 6   AvgLength                5129 non-null   float64       \n",
      " 7   FileDuration             5129 non-null   float64       \n",
      " 8   HectometerHead           5129 non-null   float64       \n",
      " 9   HectometerTail           5129 non-null   float64       \n",
      " 10  RouteNumber              5129 non-null   float64       \n",
      " 11  HectometerDirection      0 non-null      float64       \n",
      " 12  HeadSegmentFrom          0 non-null      float64       \n",
      " 13  HeadSegmentTo            0 non-null      float64       \n",
      " 14  TrajectoryFrom           5129 non-null   category      \n",
      " 15  TrajectoryTo             5129 non-null   category      \n",
      " 16  CauseGroundDetail        5129 non-null   category      \n",
      " 17  Hour                     5129 non-null   object        \n",
      " 18  Station                  5129 non-null   float64       \n",
      " 19  Date                     5129 non-null   datetime64[ns]\n",
      " 20  WindDirection            5129 non-null   float64       \n",
      " 21  WindSpeedAvg             5129 non-null   float64       \n",
      " 22  WindSpeed                5129 non-null   float64       \n",
      " 23  WindGust                 5129 non-null   float64       \n",
      " 24  Temperature              5129 non-null   float64       \n",
      " 25  MinTemp10cm              5129 non-null   category      \n",
      " 26  DewPoint                 5129 non-null   float64       \n",
      " 27  SunshineDuration         5129 non-null   float64       \n",
      " 28  GlobalRadiation          5129 non-null   float64       \n",
      " 29  PrecipitationDuration    5129 non-null   float64       \n",
      " 30  PrecipitationAmount      5129 non-null   float64       \n",
      " 31  AirPressure              5129 non-null   float64       \n",
      " 32  Visibility               5129 non-null   float64       \n",
      " 33  CloudCover               5129 non-null   float64       \n",
      " 34  Humidity                 5129 non-null   float64       \n",
      " 35  Weather                  5129 non-null   object        \n",
      " 36  WeatherCode              5129 non-null   float64       \n",
      " 37  Fog                      5129 non-null   float64       \n",
      " 38  Rain                     5129 non-null   float64       \n",
      " 39  Snow                     5129 non-null   float64       \n",
      " 40  Thunder                  5129 non-null   float64       \n",
      " 41  IceFormation             5129 non-null   float64       \n",
      " 42  WayOfTraffic             5129 non-null   object        \n",
      " 43  Hour.1                   49715 non-null  object        \n",
      " 44  Station.1                49715 non-null  int64         \n",
      " 45  Date.1                   21995 non-null  object        \n",
      " 46  WindDirection.1          49715 non-null  int64         \n",
      " 47  WindSpeedAvg.1           49715 non-null  int64         \n",
      " 48  WindSpeed.1              49715 non-null  int64         \n",
      " 49  WindGust.1               49715 non-null  int64         \n",
      " 50  Temperature.1            49715 non-null  int64         \n",
      " 51  MinTemp10cm.1            49715 non-null  object        \n",
      " 52  DewPoint.1               49715 non-null  int64         \n",
      " 53  SunshineDuration.1       49715 non-null  int64         \n",
      " 54  GlobalRadiation.1        49715 non-null  int64         \n",
      " 55  PrecipitationDuration.1  49715 non-null  int64         \n",
      " 56  PrecipitationAmount.1    49715 non-null  int64         \n",
      " 57  AirPressure.1            49715 non-null  int64         \n",
      " 58  Visibility.1             49715 non-null  int64         \n",
      " 59  CloudCover.1             49715 non-null  object        \n",
      " 60  Humidity.1               49715 non-null  int64         \n",
      " 61  Weather.1                49715 non-null  object        \n",
      " 62  WeatherCode.1            49715 non-null  int64         \n",
      " 63  Fog.1                    49715 non-null  int64         \n",
      " 64  Rain.1                   49715 non-null  int64         \n",
      " 65  Snow.1                   49715 non-null  int64         \n",
      " 66  Thunder.1                49715 non-null  int64         \n",
      " 67  IceFormation.1           49715 non-null  int64         \n",
      "dtypes: category(4), datetime64[ns](5), float64(31), int64(20), object(8)\n",
      "memory usage: 24.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\botna\\AppData\\Local\\Temp\\ipykernel_25788\\643458853.py:1: DtypeWarning: Columns (1,2,3,4,11,12,13,14,15,16,17,19,25,35,42,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  a2 = pd.read_csv('see.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    NLSituationNumber DateFileStart DateFileEnd TimeFileStart TimeFileEnd  \\\n",
       " 0                NaN           NaT         NaT           NaT         NaT   \n",
       " 1                NaN           NaT         NaT           NaT         NaT   \n",
       " 2                NaN           NaT         NaT           NaT         NaT   \n",
       " 3                NaN           NaT         NaT           NaT         NaT   \n",
       " 4                NaN           NaT         NaT           NaT         NaT   \n",
       " \n",
       "    FileSeverity  AvgLength  FileDuration  HectometerHead  HectometerTail  ...  \\\n",
       " 0           NaN        NaN           NaN             NaN             NaN  ...   \n",
       " 1           NaN        NaN           NaN             NaN             NaN  ...   \n",
       " 2           NaN        NaN           NaN             NaN             NaN  ...   \n",
       " 3           NaN        NaN           NaN             NaN             NaN  ...   \n",
       " 4           NaN        NaN           NaN             NaN             NaN  ...   \n",
       " \n",
       "    Visibility.1  CloudCover.1  Humidity.1  Weather.1 WeatherCode.1 Fog.1  \\\n",
       " 0            22             8          96         23             7     0   \n",
       " 1            47             8          94         23             7     0   \n",
       " 2            56             8          93         10             7     0   \n",
       " 3            57             8          92         10             7     0   \n",
       " 4            56             8          92         10             7     0   \n",
       " \n",
       "   Rain.1 Snow.1  Thunder.1 IceFormation.1  \n",
       " 0      1      0          0              0  \n",
       " 1      1      0          0              0  \n",
       " 2      0      0          0              0  \n",
       " 3      0      0          0              0  \n",
       " 4      0      0          0              0  \n",
       " \n",
       " [5 rows x 68 columns])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = pd.read_csv('see.csv')\n",
    "\n",
    "# Convert date and time columns to datetime\n",
    "a2['DateFileStart'] = pd.to_datetime(a2['DateFileStart'], errors='coerce')\n",
    "a2['DateFileEnd'] = pd.to_datetime(a2['DateFileEnd'], errors='coerce')\n",
    "a2['Date'] = pd.to_datetime(a2['Date'], errors='coerce')\n",
    "a2['TimeFileStart'] = pd.to_datetime(a2['TimeFileStart'], errors='coerce', format='%H:%M:%S').dt.time\n",
    "a2['TimeFileEnd'] = pd.to_datetime(a2['TimeFileEnd'], errors='coerce', format='%H:%M:%S').dt.time\n",
    "a2['Hour'] = pd.to_datetime(a2['Hour'], errors='coerce', format='%H:%M:%S').dt.time\n",
    "\n",
    "# Check and report missing columns before conversion\n",
    "float_columns = ['FileSeverity', 'AvgLength', 'FileDuration', 'HectometerHead', 'HectometerTail', 'RouteNumber',\n",
    "                 'Station', 'WindDirection', 'WindSpeedAvg', 'WindSpeed', 'WindGust', 'Temperature', \n",
    "                 'DewPoint', 'SunshineDuration', 'GlobalRadiation', 'PrecipitationDuration', \n",
    "                 'PrecipitationAmount', 'HectometerDirection', 'HeadSegmentFrom', 'HeadSegmentTo']\n",
    "\n",
    "missing_float_columns = [col for col in float_columns if col not in a2.columns]\n",
    "print(f\"Missing float columns: {missing_float_columns}\")\n",
    "\n",
    "# Convert present columns to float\n",
    "for col in float_columns:\n",
    "    if col in a2.columns:\n",
    "        a2[col] = pd.to_numeric(a2[col], errors='coerce')\n",
    "\n",
    "# Check and report missing integer columns before conversion\n",
    "int_columns = ['NLSituationNumber']\n",
    "\n",
    "missing_int_columns = [col for col in int_columns if col not in a2.columns]\n",
    "print(f\"Missing integer columns: {missing_int_columns}\")\n",
    "\n",
    "# Convert present columns to integer\n",
    "for col in int_columns:\n",
    "    if col in a2.columns:\n",
    "        a2[col] = pd.to_numeric(a2[col], errors='coerce', downcast='integer')\n",
    "\n",
    "# Check and report missing categorical columns before conversion\n",
    "categorical_columns = ['TrajectoryFrom', 'TrajectoryTo', 'CauseGroundDetail', 'MinTemp10cm']\n",
    "\n",
    "missing_categorical_columns = [col for col in categorical_columns if col not in a2.columns]\n",
    "print(f\"Missing categorical columns: {missing_categorical_columns}\")\n",
    "\n",
    "# Convert present columns to category type\n",
    "for col in categorical_columns:\n",
    "    if col in a2.columns:\n",
    "        a2[col] = a2[col].astype('category')\n",
    "\n",
    "# Verify the changes\n",
    "df_info_updated = a2.info()\n",
    "df_head_updated = a2.head()\n",
    "\n",
    "df_info_updated, df_head_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot setitem on a Categorical with a new category (0), set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Replace NaN values in specified columns with 0\u001b[39;00m\n\u001b[0;32m     21\u001b[0m columns_to_fill \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNLSituationNumber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileSeverity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvgLength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileDuration\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHectometerHead\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHectometerTail\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRouteNumber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHectometerDirection\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeadSegmentFrom\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     23\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeadSegmentTo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrajectoryFrom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrajectoryTo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 25\u001b[0m a2[columns_to_fill] \u001b[38;5;241m=\u001b[39m \u001b[43ma2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_fill\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Replace NaN values in specified columns with \"No Incident\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCauseGroundDetail\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCauseGroundDetail\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Incident\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:7431\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   7429\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_mgr\n\u001b[0;32m   7430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 7431\u001b[0m         new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[0;32m   7433\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7434\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   7435\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotna(), value)\u001b[38;5;241m.\u001b[39m_mgr\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:186\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2334\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[1;34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[0m\n\u001b[0;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2332\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2334\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2335\u001b[0m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2338\u001b[0m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray.fillna added a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2345\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2346\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:372\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[1;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[1;32m--> 372\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:261\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     key \u001b[38;5;241m=\u001b[39m check_array_indexer(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m--> 261\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1589\u001b[0m, in \u001b[0;36mCategorical._validate_setitem_value\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_listlike(value)\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1614\u001b[0m, in \u001b[0;36mCategorical._validate_scalar\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbox_scalar(fill_value)\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot setitem on a Categorical with a new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfill_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), set the categories first\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1617\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fill_value\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot setitem on a Categorical with a new category (0), set the categories first"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming a2 is the DataFrame already loaded and processed up to the previous steps\n",
    "\n",
    "# Transform 'Date' to 'dd/mm/yyyy' format (considering it might already be in 'dd/mm/yyyy' format)\n",
    "a2['Date'] = pd.to_datetime(a2['Date'], dayfirst=True).dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\n",
    "a2['DateFileStart'] = a2['DateFileStart'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "a2['DateFileEnd'] = a2['DateFileEnd'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "\n",
    "# Replace NaN values in 'TimeFileStart' and 'TimeFileEnd' with 'Hour'\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].fillna(a2['Hour'])\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].fillna(a2['Hour'])\n",
    "\n",
    "# Ensure 'TimeFileStart' and 'TimeFileEnd' are in the correct format\n",
    "a2['TimeFileStart'] = pd.to_datetime(a2['TimeFileStart'], format='%H:%M:%S').dt.strftime('%H:%M:%S')\n",
    "a2['TimeFileEnd'] = pd.to_datetime(a2['TimeFileEnd'], format='%H:%M:%S').dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Replace NaN values in specified columns with 0\n",
    "columns_to_fill = ['NLSituationNumber', 'FileSeverity', 'AvgLength', 'FileDuration',\n",
    "                   'HectometerHead', 'HectometerTail', 'RouteNumber', 'HectometerDirection', 'HeadSegmentFrom', \n",
    "                   'HeadSegmentTo', 'TrajectoryFrom', 'TrajectoryTo']\n",
    "\n",
    "a2[columns_to_fill] = a2[columns_to_fill].fillna(0)\n",
    "\n",
    "# Replace NaN values in specified columns with \"No Incident\"\n",
    "a2['CauseGroundDetail'] = a2['CauseGroundDetail'].fillna(\"No Incident\")\n",
    "\n",
    "# Drop unnecessary columns if needed\n",
    "# columns_to_drop = ['RouteLetter', 'RouteDescription', 'CauseProgress', 'CauseCodeProgress', 'Cause1', 'Cause2', 'Cause3', 'Cause4']\n",
    "# a2 = a2.drop(columns=columns_to_drop)\n",
    "\n",
    "a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLSituationNumber            0\n",
       "DateFileStart            27720\n",
       "DateFileEnd              27720\n",
       "TimeFileStart                0\n",
       "TimeFileEnd                  0\n",
       "FileSeverity                 0\n",
       "AvgLength                    0\n",
       "FileDuration                 0\n",
       "HectometerHead               0\n",
       "HectometerTail               0\n",
       "RouteNumber                  0\n",
       "HectometerDirection          0\n",
       "HeadSegmentFrom              0\n",
       "HeadSegmentTo                0\n",
       "TrajectoryFrom               0\n",
       "TrajectoryTo                 0\n",
       "CauseGroundDetail            0\n",
       "WayOfTraffic             44586\n",
       "Hour                         0\n",
       "Station                      0\n",
       "Date                     27720\n",
       "WindDirection                0\n",
       "WindSpeedAvg                 0\n",
       "WindSpeed                    0\n",
       "WindGust                     0\n",
       "Temperature                  0\n",
       "MinTemp10cm                  0\n",
       "DewPoint                     0\n",
       "SunshineDuration             0\n",
       "GlobalRadiation              0\n",
       "PrecipitationDuration        0\n",
       "PrecipitationAmount          0\n",
       "AirPressure                  0\n",
       "Visibility                   0\n",
       "CloudCover                   0\n",
       "Humidity                     0\n",
       "Weather                      0\n",
       "WeatherCode                  0\n",
       "Fog                          0\n",
       "Rain                         0\n",
       "Snow                         0\n",
       "Thunder                      0\n",
       "IceFormation                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\botna\\AppData\\Local\\Temp\\ipykernel_25788\\2190974107.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(a2[column]):\n",
      "C:\\Users\\botna\\AppData\\Local\\Temp\\ipykernel_25788\\2190974107.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(a2[column]):\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot setitem on a Categorical with a new category (No Incident), set the categories first",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m a2[columns_to_fill] \u001b[38;5;241m=\u001b[39m a2[columns_to_fill]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Step 6: Replace NaN values in 'CauseGroundDetail' with \"No Incident\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCauseGroundDetail\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43ma2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCauseGroundDetail\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNo Incident\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m a2\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:7346\u001b[0m, in \u001b[0;36mNDFrame.fillna\u001b[1;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[0;32m   7339\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   7341\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter must be a scalar, dict \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   7342\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Series, but you passed a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   7343\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   7344\u001b[0m         )\n\u001b[1;32m-> 7346\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\n\u001b[0;32m   7348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7350\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[0;32m   7351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\base.py:186\u001b[0m, in \u001b[0;36mDataManager.fillna\u001b[1;34m(self, value, limit, inplace, downcast)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     limit \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mvalidate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit\u001b[38;5;241m=\u001b[39mlimit)\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfillna\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2334\u001b[0m, in \u001b[0;36mExtensionBlock.fillna\u001b[1;34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[0m\n\u001b[0;32m   2331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   2332\u001b[0m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[0;32m   2333\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2334\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2335\u001b[0m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2338\u001b[0m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtensionArray.fillna added a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword in pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2345\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   2346\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:372\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.fillna\u001b[1;34m(self, value, method, limit, copy)\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    371\u001b[0m             new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[:]\n\u001b[1;32m--> 372\u001b[0m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# We validate the fill_value even if there is nothing to fill\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\_mixins.py:261\u001b[0m, in \u001b[0;36mNDArrayBackedExtensionArray.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m     key \u001b[38;5;241m=\u001b[39m check_array_indexer(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m--> 261\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1589\u001b[0m, in \u001b[0;36mCategorical._validate_setitem_value\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_listlike(value)\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:1614\u001b[0m, in \u001b[0;36mCategorical._validate_scalar\u001b[1;34m(self, fill_value)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unbox_scalar(fill_value)\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1614\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1615\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot setitem on a Categorical with a new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1616\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfill_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), set the categories first\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1617\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fill_value\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot setitem on a Categorical with a new category (No Incident), set the categories first"
     ]
    }
   ],
   "source": [
    "# Identify and parse dates in mixed formats\n",
    "a2['Date'] = pd.to_datetime(a2['Date'], errors='coerce', format='%Y-%m-%d').fillna(pd.to_datetime(a2['Date'], errors='coerce', format='%d/%m/%Y'))\n",
    "a2['Date'] = a2['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Step 2: Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\n",
    "a2['DateFileStart'] = a2['DateFileStart'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "a2['DateFileEnd'] = a2['DateFileEnd'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "\n",
    "# Step 3: Replace NaN values in 'TimeFileStart' and 'TimeFileEnd' with 'Hour' and extract only the time part\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S').dt.time)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S').dt.time)\n",
    "\n",
    "# Ensure 'TimeFileStart' and 'TimeFileEnd' are in the correct format\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].apply(lambda x: x.strftime('%H:%M:%S') if isinstance(x, pd.Timestamp) else x)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].apply(lambda x: x.strftime('%H:%M:%S') if isinstance(x, pd.Timestamp) else x)\n",
    "\n",
    "# Step 5: Replace NaN values in specified columns with 0\n",
    "columns_to_fill = ['NLSituationNumber', 'FileSeverity', 'AvgLength', 'FileDuration',\n",
    "                   'HectometerHead', 'HectometerTail', 'RouteNumber', 'HectometerDirection', 'HeadSegmentFrom', \n",
    "                   'HeadSegmentTo', 'TrajectoryFrom', 'TrajectoryTo']\n",
    "\n",
    "# To avoid the TypeError, convert categorical columns to string type before filling NaN values\n",
    "for column in columns_to_fill:\n",
    "    if pd.api.types.is_categorical_dtype(a2[column]):\n",
    "        a2[column] = a2[column].astype(str)\n",
    "\n",
    "a2[columns_to_fill] = a2[columns_to_fill].fillna(0)\n",
    "\n",
    "# Step 6: Replace NaN values in 'CauseGroundDetail' with \"No Incident\"\n",
    "a2['CauseGroundDetail'] = a2['CauseGroundDetail'].fillna(\"No Incident\")\n",
    "\n",
    "a2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['Accidents', 'EmergencyandPolice', 'Obstacles', 'Other',\n",
       "                  'Roadworks and Maintenance', 'TrafficJams', 'Vehicle Issues',\n",
       "                  'Weather'],\n",
       ", ordered=False, categories_dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2['CauseGroundDetail'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"02/01/2019\" doesn't match format \"%Y%m%d\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming merged_data is already loaded and processed up to the previous steps\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Transform 'YYYYMMDD' in 'Date' to 'dd/mm/yyyy' format\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(pd\u001b[38;5;241m.\u001b[39mto_datetime(a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"02/01/2019\" doesn't match format \"%Y%m%d\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Assuming merged_data is already loaded and processed up to the previous steps\n",
    "\n",
    "# Transform 'YYYYMMDD' in 'Date' to 'dd/mm/yyyy' format\n",
    "a2['Date'] = pd.to_datetime(a2['Date'], format='%Y%m%d').dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\n",
    "a2['DateFileStart'] = a2['DateFileStart'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "a2['DateFileEnd'] = a2['DateFileEnd'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "\n",
    "# Replace NaN values in 'TimeFileStart' and 'TimeFileEnd' with 'Hour' and extract only the time part\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S').dt.time)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S').dt.time)\n",
    "\n",
    "# Ensure 'TimeFileStart' and 'TimeFileEnd' are in the correct format\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].apply(lambda x: x.strftime('%H:%M:%S') if not pd.isnull(x) else x)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].apply(lambda x: x.strftime('%H:%M:%S') if not pd.isnull(x) else x)\n",
    "\n",
    "# Replace NaN values in specified columns with 0\n",
    "columns_to_fill = ['NLSituationNumber', 'FileSeverity', 'AvgLength', 'FileDuration',\n",
    "                   'HectometerHead', 'HectometerTail', 'RouteNumber', 'HectometerDirection', 'HeadSegmentFrom', \n",
    "                   'HeadSegmentTo', 'TrajectoryFrom', 'TrajectoryTo']\n",
    "\n",
    "a2[columns_to_fill] = a2[columns_to_fill].fillna(0)\n",
    "\n",
    "# Replace NaN values in specified columns with \"No Incident\"\n",
    "a2['CauseGroundDetail'] = a2['CauseGroundDetail'].fillna(\"No Incident\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "# columns_to_drop = ['RouteLetter', 'RouteDescription', 'CauseProgress', 'CauseCodeProgress', 'Cause1', 'Cause2', 'Cause3', 'Cause4']\n",
    "# merged_data = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"02/01/2019\" doesn't match format \"%Y%m%d\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Transform 'YYYYMMDD' in 'Date' to 'dd/mm/yyyy' format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateFileStart\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(pd\u001b[38;5;241m.\u001b[39mto_datetime(a2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\botna\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"02/01/2019\" doesn't match format \"%Y%m%d\", at position 1. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "# Transform 'YYYYMMDD' in 'Date' to 'dd/mm/yyyy' format\n",
    "a2['Date'] = pd.to_datetime(a2['Date'], format='%Y%m%d').dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Replace NaN values in 'DateFileStart' and 'DateFileEnd' with 'Date'\n",
    "a2['DateFileStart'] = a2['DateFileStart'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "a2['DateFileEnd'] = a2['DateFileEnd'].fillna(pd.to_datetime(a2['Date'], format='%d/%m/%Y'))\n",
    "\n",
    "# Replace NaN values in 'TimeFileStart' and 'TimeFileEnd' with 'Hour' and extract only the time part\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S', errors='coerce').dt.time)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].fillna(pd.to_datetime(a2['Hour'], format='%H:%M:%S', errors='coerce').dt.time)\n",
    "\n",
    "# Ensure 'TimeFileStart' and 'TimeFileEnd' are in the correct format\n",
    "a2['TimeFileStart'] = a2['TimeFileStart'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notnull(x) else x)\n",
    "a2['TimeFileEnd'] = a2['TimeFileEnd'].apply(lambda x: x.strftime('%H:%M:%S') if pd.notnull(x) else x)\n",
    "\n",
    "# Replace NaN values in specified columns with 0\n",
    "columns_to_fill = ['NLSituationNumber', 'FileSeverity', 'AvgLength', 'FileDuration',\n",
    "                   'HectometerHead', 'HectometerTail', 'RouteNumber', 'HectometerDirection', 'HeadSegmentFrom', \n",
    "                   'HeadSegmentTo', 'TrajectoryFrom', 'TrajectoryTo']\n",
    "\n",
    "a2[columns_to_fill] = a2[columns_to_fill].fillna(0)\n",
    "\n",
    "# Replace NaN values in specified columns with \"No Incident\"\n",
    "a2['CauseGroundDetail'] = a2['CauseGroundDetail'].fillna(\"No Incident\")\n",
    "\n",
    "a2.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
